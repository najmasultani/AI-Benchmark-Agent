from dotenv import load_dotenv
from src.workflow import Workflow

load_dotenv()


def main():
    workflow = Workflow()
    print("AI Benchmark Evaluation Agent")

    while True:
        query = input("\nğŸ” Benchmark Query (e.g., 'fast NLP models for QA'): ").strip()
        if query.lower() in {"quit", "exit"}:
            break

        if query:
            result = workflow.run(query)
            print(f"\nğŸ“Š Results for: {query}")
            print("=" * 60)

            for i, m in enumerate(result.models, 1):
                print(f"\n{i}. ğŸ§  {m.name}")
                print(f"   ğŸ”— Source: {m.source_url}")
                if m.task:
                    print(f"   ğŸ¯ Task: {m.task}")
                if m.params:
                    print(f"   ğŸ§® Params: {m.params}")
                if m.latency:
                    print(f"   âš¡ Latency: {m.latency}")
                if m.memory_footprint:
                    print(f"   ğŸ—„ï¸  Memory: {m.memory_footprint}")
                if m.license:
                    print(f"   ğŸ“œ License: {m.license}")
                if m.openness:
                    print(f"   ğŸ”“ Openness: {m.openness}")
                if m.benchmarks:
                    top = ", ".join([f"{k}: {v}" for k, v in list(m.benchmarks.items())[:5]])
                    print(f"   ğŸ§ª Benchmarks: {top}")
                if m.recommended_usage:
                    print(f"   âœ… Good for: {', '.join(m.recommended_usage[:4])}")
                if m.strengths:
                    print(f"   ğŸ‘ Strengths: {', '.join(m.strengths[:3])}")
                if m.limitations:
                    print(f"   âš ï¸ Limitations: {', '.join(m.limitations[:3])}")
                if m.description and m.description != "Analysis failed":
                    print(f"   ğŸ“ Summary: {m.description}")

            if result.analysis:
                print("\nRecommendation:")
                print("-" * 40)
                print(result.analysis)


if __name__ == "__main__":
    main()
